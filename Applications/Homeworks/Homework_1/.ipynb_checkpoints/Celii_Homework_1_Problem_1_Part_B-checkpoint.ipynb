{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To implement hoemwork 1 problems for ELEC 479/578\\n\\nHelpful links: \\nhttp://www.neural.cz/dataset-exploration-boston-house-pricing.html\\n\\nInstallations required \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To implement hoemwork 1 problems for ELEC 479/578\n",
    "\n",
    "Helpful links: \n",
    "http://www.neural.cz/dataset-exploration-boston-house-pricing.html\n",
    "\n",
    "Installations required \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"../../../machine_learning_tools/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_utils as sklu\n",
    "import pandas_ml as pdml\n",
    "import seaborn_ml as sml\n",
    "import sklearn_models as sklm\n",
    "import feature_selection_utils as fsu\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\",1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset (alreaady drops nan falues)\n",
    "target_name = \"MEDV\"\n",
    "df_raw = sklu.load_boston()\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary analysis of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdml.df_column_summaries(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RM         0.695360\n",
       "ZN         0.360445\n",
       "B          0.333461\n",
       "DIS        0.249929\n",
       "CHAS       0.175260\n",
       "AGE       -0.376955\n",
       "RAD       -0.381626\n",
       "CRIM      -0.388305\n",
       "NOX       -0.427321\n",
       "TAX       -0.468536\n",
       "INDUS     -0.483725\n",
       "PTRATIO   -0.507787\n",
       "LSTAT     -0.737663\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdml.correlations_to_target(df_raw,target_name = \"MEDV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdml.center_df(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nObservation: The distribution of the data is not necessarily normal for all of the features\\n- StandarScalar that makes the data normalized may not be suitable\\n\\nWas going to use the RobustScaler for scaling all fo the features\\nbut the documentation for elastic net then recommended the StandardScalar\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Observation: The distribution of the data is not necessarily normal for all of the features\n",
    "- StandarScalar that makes the data normalized may not be suitable\n",
    "\n",
    "Was going to use the RobustScaler for scaling all fo the features\n",
    "but the documentation for elastic net then recommended the StandardScalar\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>1.467194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.932806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>12.167194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>10.867194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>13.667194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.413229</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.439316</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>-0.625796</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.387217</td>\n",
       "      <td>-0.418147</td>\n",
       "      <td>-0.132806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.415249</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.234548</td>\n",
       "      <td>0.288933</td>\n",
       "      <td>-0.716639</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.500850</td>\n",
       "      <td>-1.932806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.413447</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>-0.773684</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.983048</td>\n",
       "      <td>1.367194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.407764</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.725672</td>\n",
       "      <td>0.736996</td>\n",
       "      <td>-0.668437</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.403225</td>\n",
       "      <td>-0.865302</td>\n",
       "      <td>-0.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.415000</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.362767</td>\n",
       "      <td>0.434732</td>\n",
       "      <td>-0.613246</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.669058</td>\n",
       "      <td>-10.632806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1   -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2   -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3   -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4   -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501 -0.413229 -0.487722  0.115738 -0.272599  0.158124  0.439316  0.018673   \n",
       "502 -0.415249 -0.487722  0.115738 -0.272599  0.158124 -0.234548  0.288933   \n",
       "503 -0.413447 -0.487722  0.115738 -0.272599  0.158124  0.984960  0.797449   \n",
       "504 -0.407764 -0.487722  0.115738 -0.272599  0.158124  0.725672  0.736996   \n",
       "505 -0.415000 -0.487722  0.115738 -0.272599  0.158124 -0.362767  0.434732   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT       MEDV  \n",
       "0    0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562   1.467194  \n",
       "1    0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  -0.932806  \n",
       "2    0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  12.167194  \n",
       "3    1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  10.867194  \n",
       "4    1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  13.667194  \n",
       "..        ...       ...       ...       ...       ...       ...        ...  \n",
       "501 -0.625796 -0.982843 -0.803212  1.176466  0.387217 -0.418147  -0.132806  \n",
       "502 -0.716639 -0.982843 -0.803212  1.176466  0.441052 -0.500850  -1.932806  \n",
       "503 -0.773684 -0.982843 -0.803212  1.176466  0.441052 -0.983048   1.367194  \n",
       "504 -0.668437 -0.982843 -0.803212  1.176466  0.403225 -0.865302  -0.532806  \n",
       "505 -0.613246 -0.982843 -0.803212  1.176466  0.441052 -0.669058 -10.632806  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocessing_ml as preml\n",
    "df_scaled = preml.scale_df(df,\n",
    "            target_name=target_name,\n",
    "            scaler = \"StandardScaler\",\n",
    "            verbose = False)\n",
    "df_scaled[target_name] = df[target_name]\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure they are now standardized\n",
    "#df_scaled.mean(),df_scaled.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = pdml.X_y(df_scaled,target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Which linear method is best for prediction? For this part of the problem, you will need to\n",
    "1) randomly split the data into 60% training, 20% validation and 20% test sets. \n",
    "\n",
    "For those with tuning parameters:\n",
    "a) you should fit models on the training data, \n",
    "b) choose the tuning parameters by minimizing the prediction error on the validation set\n",
    "c) and then report the final prediction erroron the test set. \n",
    "\n",
    "\n",
    "Repeat this procedure 10 times and average the results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Working on Iteration: 0 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2470ee7c40941d4a20f7917d0dbaa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088b9e2590b24ed1801c3f94e814b133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 6\n",
      "lasso_adapt_alpha = 0.027159813946793773\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_adapt_alpha = 0.027159813946793773\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_alpha = 0.040257356240404045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b710ead1a945a48f5fe13c342889b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.98010101010101\n",
      "\n",
      "best_subset_features= ('CHAS', 'NOX', 'RM', 'DIS', 'PTRATIO', 'B', 'LSTAT')\n",
      "best_rfe_features = ['RM' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.010909801232920851\n",
      "Total time for iteration 0: 186.0049455165863\n",
      "\n",
      "======= Working on Iteration: 1 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ba47ad2441484c84e3f999a212ef58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512a50390c2d42079189cc059cd68af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 9\n",
      "lasso_adapt_alpha = 0.026327517382885784\n",
      "\n",
      "ridge_alpha = 1.0\n",
      "\n",
      "lasso_adapt_alpha = 0.026327517382885784\n",
      "\n",
      "ridge_alpha = 1.0\n",
      "\n",
      "lasso_alpha = 0.006565350244645095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63302cf166044acbe36df53ddb366eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('CRIM', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'PTRATIO', 'B', 'LSTAT')\n",
      "best_rfe_features = ['CRIM' 'ZN' 'NOX' 'RM' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.008175828931723111\n",
      "Total time for iteration 1: 174.38327050209045\n",
      "\n",
      "======= Working on Iteration: 2 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e861c786e24d319dcb9c23e0e15654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17288b2942994da88de0d75d2af0e8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 7\n",
      "lasso_adapt_alpha = 0.026793170183638707\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_adapt_alpha = 0.026793170183638707\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_alpha = 0.030426310695653026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea997932832438fa8ac36f7caabdc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('CHAS', 'NOX', 'RM', 'DIS', 'PTRATIO', 'LSTAT')\n",
      "best_rfe_features = ['NOX' 'RM' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.026730558970588892\n",
      "Total time for iteration 2: 196.0523030757904\n",
      "\n",
      "======= Working on Iteration: 3 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8399ecdfe55477b93c0376c19e5ab6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c7fff9ab73428db539c453dff544f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 7\n",
      "lasso_adapt_alpha = 0.025688268892371236\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_adapt_alpha = 0.025688268892371236\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_alpha = 0.030145045976802457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6c1dca8b0143b9bd5448d34a72c38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('CRIM', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'PTRATIO', 'LSTAT')\n",
      "best_rfe_features = ['NOX' 'RM' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.016250004413038432\n",
      "Total time for iteration 3: 170.1099705696106\n",
      "\n",
      "======= Working on Iteration: 4 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf24de9e9c28484db71e82cc4962ede2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ee53edf06b45028799908b40625e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 5\n",
      "lasso_adapt_alpha = 0.027133023575133162\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_adapt_alpha = 0.027133023575133162\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_alpha = 0.02359504589665408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0e56abc5384feca27cd1c544b2ff0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('RM', 'PTRATIO', 'LSTAT')\n",
      "best_rfe_features = ['NOX' 'RM' 'DIS' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.02740259502667541\n",
      "Total time for iteration 4: 161.97638392448425\n",
      "\n",
      "======= Working on Iteration: 5 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e209e33387c47cebcb1f3ea1219235b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7402465e52034529819ffa5b86d8ba45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 5\n",
      "lasso_adapt_alpha = 0.027061103632670676\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_adapt_alpha = 0.027061103632670676\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_alpha = 0.02769641447069747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6735b39aaea4e518d86587396525e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('RM', 'PTRATIO', 'LSTAT')\n",
      "best_rfe_features = ['RM' 'RAD' 'TAX' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.01973663927338363\n",
      "Total time for iteration 5: 181.7150683403015\n",
      "\n",
      "======= Working on Iteration: 6 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a62ddfa8e6419a9c1edaf90757b31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7250b77789e64ad890c2bd0626710fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 7\n",
      "lasso_adapt_alpha = 0.034028261946667616\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_adapt_alpha = 0.034028261946667616\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_alpha = 0.03543554258682016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d99d62c8af14abdb34dde399ee885d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('NOX', 'RM', 'DIS', 'PTRATIO', 'LSTAT')\n",
      "best_rfe_features = ['NOX' 'RM' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.017814498027222028\n",
      "Total time for iteration 6: 169.01076459884644\n",
      "\n",
      "======= Working on Iteration: 7 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5947704120e645ae8bb8cc6421948150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b2a96e21bc423a8ea193cf3c691f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 5\n",
      "lasso_adapt_alpha = 0.024877010176951157\n",
      "\n",
      "ridge_alpha = 1.0\n",
      "\n",
      "lasso_adapt_alpha = 0.024877010176951157\n",
      "\n",
      "ridge_alpha = 1.0\n",
      "\n",
      "lasso_alpha = 0.032464343662837174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36360a57ada04dcb9f504549e7bf2339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('RM', 'DIS', 'PTRATIO', 'LSTAT')\n",
      "best_rfe_features = ['NOX' 'RM' 'DIS' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.030582177327605067\n",
      "Total time for iteration 7: 183.4960901737213\n",
      "\n",
      "======= Working on Iteration: 8 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b11f77ce6ad4a1aa294966ce03cedde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de53b2a59af4484b8ef28425bcfcff56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 5\n",
      "lasso_adapt_alpha = 0.02729641634364067\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_adapt_alpha = 0.02729641634364067\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_alpha = 0.007143570647560764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1225048e9e468ab7648e8127f4c834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('RM', 'PTRATIO', 'LSTAT')\n",
      "best_rfe_features = ['NOX' 'RM' 'DIS' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.007215727926829051\n",
      "Total time for iteration 8: 165.99902176856995\n",
      "\n",
      "======= Working on Iteration: 9 ======= \n",
      "For Train/Val/Test split of None/0.2/0.2 = 303/101/102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789f96e6e4bc49e59827df189cd5f565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_subset_optimal_k = 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ede4a8e3dfb43668c5a9c778d8de0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfe_optimal_k = 7\n",
      "lasso_adapt_alpha = 0.024097802823441258\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_adapt_alpha = 0.024097802823441258\n",
      "\n",
      "ridge_alpha = 10.0\n",
      "\n",
      "lasso_alpha = 0.006945493172055824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4329bcc7c6e4e86a9e376be257100b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_optimal_l1_ratio= 0.99\n",
      "\n",
      "best_subset_features= ('CRIM', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT')\n",
      "best_rfe_features = ['NOX' 'RM' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'LSTAT']\n",
      "model_elastic.alpha_ = 0.007015649668743253\n",
      "Total time for iteration 9: 173.56542706489563\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Models that do not need optimization of parameters:\n",
    "- Least Squares\n",
    "\n",
    "The parameter going to tune over is k\n",
    "- Best Subsets \n",
    "- Step-wise approaches\n",
    "\n",
    "(for those that don't nned parameter tuning will\n",
    "train on training and validation set)\n",
    "\n",
    "Models that do need optimization:\n",
    "- Ridge\n",
    "- Lasso\n",
    "- Elastic Net\n",
    "- Adaptive Lasso \n",
    "\n",
    "for parameter optimization in this lab going to use grid search\n",
    "\n",
    "\n",
    "Pseudocode: \n",
    "For each iteration\n",
    "1) Do the test/val/train split and create the data for the k-fold cross validation\n",
    "2) Run the hyper parameter tuning for each model type\n",
    "\n",
    "Models that do not need optimization of parameters:\n",
    "- Least Squares\n",
    "\n",
    "The parameter going to tune over is k\n",
    "- Best Subsets \n",
    "- Step-wise approaches\n",
    "\n",
    "Model that will need to be tuned for lambda and l1_ratio: \n",
    "- Elastic Net\n",
    "\n",
    "Models that have cross validation incorporated in functions:\n",
    "- Ridge\n",
    "- Lasso\n",
    "- Adaptive Lasso \n",
    "\n",
    "3) Create the models using the tuned parameters from the \n",
    "training and validation dataset (because cross validation was used for hyper-parameter tuning\n",
    "then can train on whole train/val dataset)\n",
    "\n",
    "4) Find the prediction MSE on the testing dataset and store\n",
    "- store the coefficients of each model and best subsets\n",
    "\n",
    "\"\"\"\n",
    "n_iterations = 10\n",
    "n_splits = 5\n",
    "verbose = True\n",
    "import time\n",
    "\n",
    "n_featuers = pdml.n_features(X,target_name=target_name)\n",
    "iterations_dict = dict()\n",
    "\n",
    "for iter_idx in range(n_iterations):\n",
    "    if verbose:\n",
    "        print(f\"\\n======= Working on Iteration: {iter_idx} ======= \")\n",
    "    \n",
    "    st = time.time()\n",
    "    #=============== Part 1: Creating Datasets ====================\n",
    "    \n",
    "    (X_train,\n",
    "     X_val,\n",
    "     X_test,\n",
    "     y_train,\n",
    "     y_val,\n",
    "     y_test) = sklu.train_val_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size = 0.2,\n",
    "        val_size = 0.2,\n",
    "        verbose = True)\n",
    "\n",
    "    X_train_val = pd.concat([X_train,X_val])\n",
    "    y_train_val = pd.concat([y_train,y_val])\n",
    "    \n",
    "    \n",
    "    fold_dfs = sklu.k_fold_df_split(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        n_splits = n_splits)\n",
    "    \n",
    "    #=============== Part 2: Hyper-parameter tuning ====================\n",
    "    \n",
    "    \n",
    "    # --------- best subsets ----\n",
    "    best_subset_k_features = []\n",
    "\n",
    "    for k in tqdm(range(1,n_featuers+1)):\n",
    "        curr_dict = dict(k=k)\n",
    "        for fold_idx,fold_data in fold_dfs.items():\n",
    "            #training the model\n",
    "            eval_method = \"MSE\"\n",
    "            curr_best,best_model = fsu.best_subset_k(\n",
    "            df = fold_data[\"X_train\"],\n",
    "            y  = fold_data[\"y_train\"],\n",
    "            k = k,\n",
    "            model = sklm.LinearRegression(),\n",
    "            evaluation_method = eval_method,\n",
    "            verbose = False,\n",
    "            return_model = True,\n",
    "            )\n",
    "\n",
    "            #evaulating the model on the validation set\n",
    "\n",
    "            mse = sklu.MSE(fold_data[\"y_test\"],\n",
    "                 model=best_model,\n",
    "                X=fold_data[\"X_test\"][list(curr_best)])\n",
    "\n",
    "            curr_dict[f\"mse_fold_{fold_idx}\"] = mse\n",
    "        best_subset_k_features.append(curr_dict)\n",
    "\n",
    "    best_subset_df = pd.DataFrame.from_records(best_subset_k_features)\n",
    "    best_subset_df\n",
    "    \n",
    "    best_subset_optimal_k,ret_df = sklu.optimal_parameter_from_kfold_df(\n",
    "    best_subset_df,\n",
    "    parameter_name = \"k\",\n",
    "    columns_prefix = \"mse_fold\",\n",
    "    higher_param_higher_complexity = True,\n",
    "    standard_error_buffer = True,\n",
    "    verbose = False,\n",
    "    return_df = True\n",
    "                                 )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"best_subset_optimal_k = {best_subset_optimal_k}\")\n",
    "    \n",
    "    \n",
    "    #--------- RFE model ---------------\n",
    "    rfe_k_features = []\n",
    "\n",
    "    for k in tqdm(range(1,n_featuers+1)):\n",
    "        curr_dict = dict(k=k)\n",
    "        for fold_idx,fold_data in fold_dfs.items():\n",
    "            #training the model\n",
    "            curr_best,best_model = fsu.reverse_feature_elimination(\n",
    "            df = fold_data[\"X_train\"],\n",
    "            y  = fold_data[\"y_train\"],\n",
    "            k = k,\n",
    "            model = sklm.LinearRegression(),\n",
    "            verbose = False,\n",
    "            return_model = True,\n",
    "            )\n",
    "\n",
    "            #evaulating the model on the validation set\n",
    "\n",
    "            mse = sklu.MSE(fold_data[\"y_test\"],\n",
    "                     model=best_model,\n",
    "                    X=fold_data[\"X_test\"][list(curr_best)])\n",
    "\n",
    "            curr_dict[f\"mse_fold_{fold_idx}\"] = mse\n",
    "\n",
    "        rfe_k_features.append(curr_dict)\n",
    "\n",
    "    rfe_df = pd.DataFrame.from_records(rfe_k_features)\n",
    "    \n",
    "    \n",
    "    rfe_optimal_k,ret_df = sklu.optimal_parameter_from_kfold_df(\n",
    "    rfe_df,\n",
    "    parameter_name = \"k\",\n",
    "    columns_prefix = \"mse_fold\",\n",
    "    higher_param_higher_complexity = True,\n",
    "    standard_error_buffer = True,\n",
    "    verbose = False,\n",
    "    return_df = True\n",
    "                                 )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"rfe_optimal_k = {rfe_optimal_k}\")\n",
    "        \n",
    "    #-------- Lamda only hyper parameters: lass, ridge and adaptive lass\n",
    "    \n",
    "    model_lasso_adapt = sklm.AdaptiveLasso(X_train_val,y_train_val,\n",
    "                                      cv_n_splits=n_splits)\n",
    "    lasso_adapt_alpha = model_lasso_adapt.alpha_\n",
    "\n",
    "    print(f\"lasso_adapt_alpha = {lasso_adapt_alpha}\\n\")\n",
    "\n",
    "\n",
    "    model_ridge = sklm.RidgeCV(cv_n_splits=n_splits)\n",
    "    model_ridge.fit(X_train_val,y_train_val)\n",
    "    ridge_alpha = model_ridge.alpha_\n",
    "\n",
    "    print(f\"ridge_alpha = {ridge_alpha}\\n\")\n",
    "\n",
    "    model_lasso = sklm.LassoCV(cv_n_splits=n_splits)\n",
    "    model_lasso.fit(X_train_val,y_train_val)\n",
    "    lasso_alpha = model_lasso.alpha_\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"lasso_adapt_alpha = {lasso_adapt_alpha}\\n\")\n",
    "        print(f\"ridge_alpha = {ridge_alpha}\\n\")\n",
    "        print(f\"lasso_alpha = {lasso_alpha}\")\n",
    "        \n",
    "        \n",
    "    # ----------- Elastic Net ----------------------\n",
    "    elastic_mse_dicts = []\n",
    "    l1_ratio = np.linspace(0.01,0.99,100)\n",
    "\n",
    "    for curr_l1_ratio in tqdm(l1_ratio):\n",
    "        curr_dict = dict(l1_ratio=curr_l1_ratio)\n",
    "        for fold_idx,fold_data in fold_dfs.items():\n",
    "            #training the model\n",
    "\n",
    "\n",
    "            model_elastic = sklm.ElasticNetCV(\n",
    "                l1_ratio = curr_l1_ratio,\n",
    "                cv_n_splits=n_splits,\n",
    "            )    \n",
    "\n",
    "            model_elastic.fit(fold_data[\"X_train\"],\n",
    "                             fold_data[\"y_train\"])    \n",
    "\n",
    "            #evaulating the model on the validation set\n",
    "\n",
    "            mse = sklu.MSE(fold_data[\"y_test\"],\n",
    "                     model=best_model,\n",
    "                    X=fold_data[\"X_test\"])\n",
    "\n",
    "            curr_dict[f\"mse_fold_{fold_idx}\"] = mse\n",
    "            curr_dict[f\"mse_fold_{fold_idx}_alpha\"] = model_elastic.alpha_\n",
    "\n",
    "        elastic_mse_dicts.append(curr_dict)\n",
    "\n",
    "    elastic_df = pd.DataFrame.from_records(elastic_mse_dicts)\n",
    "    \n",
    "    elastic_optimal_l1_ratio,ret_df = sklu.optimal_parameter_from_kfold_df(\n",
    "        elastic_df,\n",
    "        parameter_name = \"l1_ratio\",\n",
    "        columns_prefix = \"mse_fold\",\n",
    "        higher_param_higher_complexity = False,\n",
    "        standard_error_buffer = False,\n",
    "        verbose = False,\n",
    "        return_df = True\n",
    "                                     )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"elastic_optimal_l1_ratio= {elastic_optimal_l1_ratio}\")\n",
    "        \n",
    "        \n",
    "    # =========== Part 3: Training tuned models ==============\n",
    "    # least squares model\n",
    "    model_least_squares = sklm.LinearRegression()\n",
    "    model_least_squares.fit(X_train_val,y_train_val)\n",
    "\n",
    "\n",
    "    best_subset_features,model_best_subset = fsu.best_subset_k(\n",
    "            df = X_train_val,\n",
    "            y  = y_train_val,\n",
    "            k = best_subset_optimal_k,\n",
    "            model = sklm.LinearRegression(),\n",
    "            evaluation_method = \"MSE\",\n",
    "            verbose = False,\n",
    "            return_model = True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    best_rfe_features,model_rfe = fsu.reverse_feature_elimination(\n",
    "    df = X_train_val,\n",
    "    y  = y_train_val,\n",
    "    k = rfe_optimal_k,\n",
    "    model = sklm.LinearRegression(),\n",
    "    verbose = False,\n",
    "    return_model = True,\n",
    "    )\n",
    "\n",
    "\n",
    "    # --- elastic net\n",
    "    model_elastic = sklm.ElasticNetCV(l1_ratio=elastic_optimal_l1_ratio,\n",
    "                                     )\n",
    "    model_elastic.fit(X_train_val,y_train_val)\n",
    "\n",
    "\n",
    "    # --- models trained on cv of the lambday by sklearn\n",
    "    model_lasso_adapt\n",
    "    model_ridge\n",
    "    model_lasso\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\")\n",
    "        print(f\"best_subset_features= {best_subset_features}\")\n",
    "        print(f\"best_rfe_features = {best_rfe_features}\")\n",
    "        print(f\"model_elastic.alpha_ = {model_elastic.alpha_}\")\n",
    "\n",
    "    # ======= Part 4: Prediction MSE on test data ==========\n",
    "    models_to_test = dict(\n",
    "        least_squares = model_least_squares,\n",
    "        best_subset = dict(model = model_best_subset,\n",
    "                           features = list(best_subset_features)),\n",
    "        rfe = dict(model = model_rfe,\n",
    "                   features = list(best_rfe_features)),\n",
    "        elastic = model_elastic,\n",
    "        lasso_adapt = model_lasso_adapt,\n",
    "        ridge = model_ridge,\n",
    "        lasso = model_lasso\n",
    "\n",
    "    )\n",
    "    \n",
    "    test_prediction_MSE = dict()\n",
    "    for model_name,m in models_to_test.items():\n",
    "        if type(m) == dict:\n",
    "            curr_model = m[\"model\"]\n",
    "            curr_MSE = sklu.MSE(y_test,model = curr_model,X=X_test[m[\"features\"]])\n",
    "        else:\n",
    "            curr_model = m\n",
    "            curr_MSE = sklu.MSE(y_test,\n",
    "                                model = curr_model,\n",
    "                                X=X_test)\n",
    "\n",
    "        test_prediction_MSE[model_name] = dict(MSE = curr_MSE,\n",
    "                                              coef_ = best_rfe_features)\n",
    "        \n",
    "    \n",
    "    test_prediction_MSE[\"best_subset\"][\"features\"] = best_subset_features\n",
    "    test_prediction_MSE[\"rfe\"][\"features\"] = best_subset_features\n",
    "    test_prediction_MSE[\"elastic\"][\"l1_ratio\"] =  elastic_optimal_l1_ratio\n",
    "\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Total time for iteration {iter_idx}: {time.time() - st}\")\n",
    "\n",
    "    iterations_dict[iter_idx] = test_prediction_MSE.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>least_squares</th>\n",
       "      <th>best_subset</th>\n",
       "      <th>rfe</th>\n",
       "      <th>elastic</th>\n",
       "      <th>lasso_adapt</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.882919</td>\n",
       "      <td>15.036616</td>\n",
       "      <td>17.006709</td>\n",
       "      <td>14.682715</td>\n",
       "      <td>14.569364</td>\n",
       "      <td>14.441630</td>\n",
       "      <td>14.416772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.340544</td>\n",
       "      <td>24.799441</td>\n",
       "      <td>21.528764</td>\n",
       "      <td>24.027470</td>\n",
       "      <td>23.922768</td>\n",
       "      <td>24.109032</td>\n",
       "      <td>24.059383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.199695</td>\n",
       "      <td>15.591350</td>\n",
       "      <td>13.490027</td>\n",
       "      <td>13.486487</td>\n",
       "      <td>13.319106</td>\n",
       "      <td>13.558586</td>\n",
       "      <td>13.477374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.101875</td>\n",
       "      <td>22.611193</td>\n",
       "      <td>20.717856</td>\n",
       "      <td>20.959075</td>\n",
       "      <td>20.840190</td>\n",
       "      <td>20.870046</td>\n",
       "      <td>20.860288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.568922</td>\n",
       "      <td>27.147208</td>\n",
       "      <td>24.982656</td>\n",
       "      <td>20.731290</td>\n",
       "      <td>20.579445</td>\n",
       "      <td>20.862908</td>\n",
       "      <td>20.698335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.520513</td>\n",
       "      <td>31.138034</td>\n",
       "      <td>30.743640</td>\n",
       "      <td>25.547981</td>\n",
       "      <td>25.442381</td>\n",
       "      <td>25.558377</td>\n",
       "      <td>25.591417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.352451</td>\n",
       "      <td>21.768603</td>\n",
       "      <td>22.336042</td>\n",
       "      <td>21.167737</td>\n",
       "      <td>20.874219</td>\n",
       "      <td>21.336333</td>\n",
       "      <td>21.092508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.721729</td>\n",
       "      <td>31.465961</td>\n",
       "      <td>28.656580</td>\n",
       "      <td>25.831428</td>\n",
       "      <td>25.646595</td>\n",
       "      <td>25.725566</td>\n",
       "      <td>25.845017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.941246</td>\n",
       "      <td>46.029601</td>\n",
       "      <td>44.669560</td>\n",
       "      <td>39.791695</td>\n",
       "      <td>39.868987</td>\n",
       "      <td>40.318342</td>\n",
       "      <td>39.789832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38.067813</td>\n",
       "      <td>38.583129</td>\n",
       "      <td>37.231129</td>\n",
       "      <td>37.919982</td>\n",
       "      <td>37.814288</td>\n",
       "      <td>38.540835</td>\n",
       "      <td>37.917989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   least_squares  best_subset        rfe    elastic  lasso_adapt      ridge  \\\n",
       "0      14.882919    15.036616  17.006709  14.682715    14.569364  14.441630   \n",
       "1      24.340544    24.799441  21.528764  24.027470    23.922768  24.109032   \n",
       "2      14.199695    15.591350  13.490027  13.486487    13.319106  13.558586   \n",
       "3      21.101875    22.611193  20.717856  20.959075    20.840190  20.870046   \n",
       "4      20.568922    27.147208  24.982656  20.731290    20.579445  20.862908   \n",
       "5      25.520513    31.138034  30.743640  25.547981    25.442381  25.558377   \n",
       "6      21.352451    21.768603  22.336042  21.167737    20.874219  21.336333   \n",
       "7      25.721729    31.465961  28.656580  25.831428    25.646595  25.725566   \n",
       "8      39.941246    46.029601  44.669560  39.791695    39.868987  40.318342   \n",
       "9      38.067813    38.583129  37.231129  37.919982    37.814288  38.540835   \n",
       "\n",
       "       lasso  \n",
       "0  14.416772  \n",
       "1  24.059383  \n",
       "2  13.477374  \n",
       "3  20.860288  \n",
       "4  20.698335  \n",
       "5  25.591417  \n",
       "6  21.092508  \n",
       "7  25.845017  \n",
       "8  39.789832  \n",
       "9  37.917989  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_df_dicts = []\n",
    "\n",
    "for idx,data in iterations_dict.items():\n",
    "    curr_dict = {k:v[\"MSE\"] for k,v in data.items()}\n",
    "    mse_df_dicts.append(curr_dict)\n",
    "    \n",
    "import pandas as pd\n",
    "mse_df = pd.DataFrame.from_records(mse_df_dicts)\n",
    "mse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std_err</th>\n",
       "      <th>std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>least_squares</th>\n",
       "      <td>24.569771</td>\n",
       "      <td>2.709081</td>\n",
       "      <td>8.566865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_subset</th>\n",
       "      <td>27.417114</td>\n",
       "      <td>3.084722</td>\n",
       "      <td>9.754748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfe</th>\n",
       "      <td>26.136296</td>\n",
       "      <td>2.988489</td>\n",
       "      <td>9.450431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elastic</th>\n",
       "      <td>24.414586</td>\n",
       "      <td>2.733486</td>\n",
       "      <td>8.644041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_adapt</th>\n",
       "      <td>24.287734</td>\n",
       "      <td>2.750965</td>\n",
       "      <td>8.699314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>24.532165</td>\n",
       "      <td>2.803626</td>\n",
       "      <td>8.865845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>24.374892</td>\n",
       "      <td>2.747403</td>\n",
       "      <td>8.688052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean   std_err   std_dev\n",
       "least_squares  24.569771  2.709081  8.566865\n",
       "best_subset    27.417114  3.084722  9.754748\n",
       "rfe            26.136296  2.988489  9.450431\n",
       "elastic        24.414586  2.733486  8.644041\n",
       "lasso_adapt    24.287734  2.750965  8.699314\n",
       "ridge          24.532165  2.803626  8.865845\n",
       "lasso          24.374892  2.747403  8.688052"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"mean\"] = mse_df.mean()\n",
    "df[\"std_err\"] = mse_df.sem()\n",
    "df[\"std_dev\"] = mse_df.std()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind=\"bar\",y=\"mean\",yerr=\"std_err\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_df.T.plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
